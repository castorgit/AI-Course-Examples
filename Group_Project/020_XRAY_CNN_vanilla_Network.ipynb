{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray (Pneumonia): CNN Network \n",
    "\n",
    "Baseline CNN Network\n",
    "\n",
    "We develop a CNN Network with four CNN layers structured in three blocks \\\n",
    "The dataset is split in three files, Train, Test and Validation \\\n",
    "The Validation dataset is too small, for this reason we modify the approach \\\n",
    "We use 80% of train for training \\\n",
    "20% of train for validation (training the network) \\\n",
    "We use the test dataset for Testing the network to obtain the final result \\\n",
    "\\\n",
    "Train accuracy 93.4%\n",
    "Val accuracy 95%\n",
    "Test accuracy 81%\n",
    "ROC 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:25.577006Z",
     "iopub.status.busy": "2021-09-21T06:50:25.576634Z",
     "iopub.status.idle": "2021-09-21T06:50:25.603025Z",
     "shell.execute_reply": "2021-09-21T06:50:25.602053Z",
     "shell.execute_reply.started": "2021-09-21T06:50:25.576967Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt    \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "import random\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # to avoid warning messages\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:25.605966Z",
     "iopub.status.busy": "2021-09-21T06:50:25.605399Z",
     "iopub.status.idle": "2021-09-21T06:50:25.611930Z",
     "shell.execute_reply": "2021-09-21T06:50:25.611215Z",
     "shell.execute_reply.started": "2021-09-21T06:50:25.605929Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH = 32\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:25.616438Z",
     "iopub.status.busy": "2021-09-21T06:50:25.614268Z",
     "iopub.status.idle": "2021-09-21T06:50:25.649779Z",
     "shell.execute_reply": "2021-09-21T06:50:25.649140Z",
     "shell.execute_reply.started": "2021-09-21T06:50:25.616404Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder structure \n",
    "#Notebook\n",
    "#    !------ chest_xray_data\n",
    "#                  !-------------train\n",
    "#                  !-------------test\n",
    "#                  !-------------val\n",
    "#\n",
    "main_path = \"./chest_xray_data/\"\n",
    "\n",
    "\n",
    "train_path = os.path.join(main_path,\"train\")\n",
    "test_path=os.path.join(main_path,\"test\")\n",
    "\n",
    "train_normal = glob.glob(train_path+\"/NORMAL/*.jpeg\")\n",
    "train_pneumonia = glob.glob(train_path+\"/PNEUMONIA/*.jpeg\")\n",
    "\n",
    "test_normal = glob.glob(test_path+\"/NORMAL/*.jpeg\")\n",
    "test_pneumonia = glob.glob(test_path+\"/PNEUMONIA/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:25.651296Z",
     "iopub.status.busy": "2021-09-21T06:50:25.651010Z",
     "iopub.status.idle": "2021-09-21T06:50:25.667932Z",
     "shell.execute_reply": "2021-09-21T06:50:25.667042Z",
     "shell.execute_reply.started": "2021-09-21T06:50:25.651262Z"
    }
   },
   "outputs": [],
   "source": [
    "train_list = [x for x in train_normal]\n",
    "train_list.extend([x for x in train_pneumonia])\n",
    "\n",
    "df_train = pd.DataFrame(np.concatenate([['Normal']*len(train_normal) , ['Pneumonia']*len(train_pneumonia)]), columns = ['class'])\n",
    "df_train['image'] = [x for x in train_list]\n",
    "\n",
    "test_list = [x for x in test_normal]\n",
    "test_list.extend([x for x in test_pneumonia])\n",
    "\n",
    "df_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*len(test_pneumonia)]), columns = ['class'])\n",
    "df_test['image'] = [x for x in test_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "The validation set has too few images, we change the structure of the datasets, we will use 80% of df_train for training, 20% of df_training for validation and df_test to verify the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:31.119375Z",
     "iopub.status.busy": "2021-09-21T06:50:31.118585Z",
     "iopub.status.idle": "2021-09-21T06:50:31.139681Z",
     "shell.execute_reply": "2021-09-21T06:50:31.138987Z",
     "shell.execute_reply.started": "2021-09-21T06:50:31.119339Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df_train, test_size = 0.20, random_state = SEED, stratify = df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4172, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, weâ€™re going to load the images from the folders and prepare them to feed our models. \n",
    "\n",
    "We begin by defining the data generators. With Keras Image Data Generator, we can rescale the pixel values and apply random transformation techniques for data augmentation on the fly. We define two different generators. The val_datagen is used to simply rescale the validation and test sets. The train_datagen includes some transformations to augment the train set.\n",
    "\n",
    "We apply those generators on each dataset using the flow_from_dataframe method. Apart from the transformations defined in each generator, the images are also resized based on the target_size set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:31.175831Z",
     "iopub.status.busy": "2021-09-21T06:50:31.172013Z",
     "iopub.status.idle": "2021-09-21T06:50:33.658002Z",
     "shell.execute_reply": "2021-09-21T06:50:33.657320Z",
     "shell.execute_reply.started": "2021-09-21T06:50:31.175748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes. Train:  (4172, 2) val :  (1044, 2) test :  (624, 2)\n",
      "Found 4172 validated image filenames belonging to 2 classes.\n",
      "Found 1044 validated image filenames belonging to 2 classes.\n",
      "Found 624 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print ('shapes. Train: ',train_df.shape, 'val : ', val_df.shape, 'test : ',df_test.shape)\n",
    "# https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                                  zoom_range = 0.1,\n",
    "                                  #rotation_range = 0.1,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "ds_train = train_datagen.flow_from_dataframe(train_df,\n",
    "                                             #directory=train_path, #dataframe contains the full paths\n",
    "                                             x_col = 'image',\n",
    "                                             y_col = 'class',\n",
    "                                             target_size = (IMG_SIZE, IMG_SIZE),\n",
    "                                             class_mode = 'binary',\n",
    "                                             batch_size = BATCH,\n",
    "                                             seed = SEED)\n",
    "\n",
    "ds_val = val_datagen.flow_from_dataframe(val_df,\n",
    "                                            #directory=train_path,\n",
    "                                            x_col = 'image',\n",
    "                                            y_col = 'class',\n",
    "                                            target_size = (IMG_SIZE, IMG_SIZE),\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size = BATCH,\n",
    "                                            seed = SEED)\n",
    "\n",
    "ds_test = val_datagen.flow_from_dataframe(df_test,\n",
    "                                            #directory=test_path,\n",
    "                                            x_col = 'image',\n",
    "                                            y_col = 'class',\n",
    "                                            target_size = (IMG_SIZE, IMG_SIZE),\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one element of the iterator (1, 224, 224, 3) (1,)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "one_item = list(itertools.islice(ds_test,1))\n",
    "a = one_item[0]\n",
    "print('Shape of one element of the iterator', a[0].shape, a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "Data is ready. Now we define the CNN network and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:33.659445Z",
     "iopub.status.busy": "2021-09-21T06:50:33.659187Z",
     "iopub.status.idle": "2021-09-21T06:50:33.665861Z",
     "shell.execute_reply": "2021-09-21T06:50:33.665031Z",
     "shell.execute_reply.started": "2021-09-21T06:50:33.659411Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting callbakcs\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    min_delta=0.0000001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "plateau = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor = 0.2,                                     \n",
    "    patience = 2,                                   \n",
    "    min_delt = 0.0000001,                                \n",
    "    cooldown = 0,                               \n",
    "    verbose = 1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s define our first model â€˜from scratchâ€™ and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:33.667482Z",
     "iopub.status.busy": "2021-09-21T06:50:33.667099Z",
     "iopub.status.idle": "2021-09-21T06:50:33.679963Z",
     "shell.execute_reply": "2021-09-21T06:50:33.679207Z",
     "shell.execute_reply.started": "2021-09-21T06:50:33.667445Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    # CNN Layers\n",
    "    \n",
    "    #Input shape = [width, height, color channels]\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Block One\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, padding='valid')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Block Two\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, padding='valid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Block Three\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    # MLP - Classification layers\n",
    "    \n",
    "    #x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    #Final Layer (Output)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[inputs], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:33.681512Z",
     "iopub.status.busy": "2021-09-21T06:50:33.681083Z",
     "iopub.status.idle": "2021-09-21T06:50:33.792110Z",
     "shell.execute_reply": "2021-09-21T06:50:33.790855Z",
     "shell.execute_reply.started": "2021-09-21T06:50:33.681477Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = get_model()\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              , optimizer = keras.optimizers.Adam(learning_rate=0.00003), metrics='binary_accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T06:50:33.793654Z",
     "iopub.status.busy": "2021-09-21T06:50:33.793409Z",
     "iopub.status.idle": "2021-09-21T07:32:47.116245Z",
     "shell.execute_reply": "2021-09-21T07:32:47.115524Z",
     "shell.execute_reply.started": "2021-09-21T06:50:33.793621Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(ds_train,\n",
    "          batch_size = BATCH, epochs = 50,\n",
    "          validation_data=ds_val,\n",
    "          callbacks=[early_stopping, plateau],\n",
    "          steps_per_epoch=(len(train_df)/BATCH),\n",
    "          validation_steps=(len(val_df)/BATCH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the accuracy of the CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T07:32:47.118055Z",
     "iopub.status.busy": "2021-09-21T07:32:47.117796Z",
     "iopub.status.idle": "2021-09-21T07:32:47.380527Z",
     "shell.execute_reply": "2021-09-21T07:32:47.379875Z",
     "shell.execute_reply.started": "2021-09-21T07:32:47.118023Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
    "sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
    "ax.set_title('Learning Curve (Loss)')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T07:32:47.382133Z",
     "iopub.status.busy": "2021-09-21T07:32:47.381888Z",
     "iopub.status.idle": "2021-09-21T07:32:47.650381Z",
     "shell.execute_reply": "2021-09-21T07:32:47.649710Z",
     "shell.execute_reply.started": "2021-09-21T07:32:47.382101Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.lineplot(x = history.epoch, y = history.history['binary_accuracy'])\n",
    "sns.lineplot(x = history.epoch, y = history.history['val_binary_accuracy'])\n",
    "ax.set_title('Learning Curve (Accuracy)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylim(0.80, 1.0)\n",
    "ax.legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:32:47.651965Z",
     "iopub.status.busy": "2021-09-21T07:32:47.651686Z",
     "iopub.status.idle": "2021-09-21T07:32:59.539926Z",
     "shell.execute_reply": "2021-09-21T07:32:59.539200Z",
     "shell.execute_reply.started": "2021-09-21T07:32:47.651932Z"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(ds_val, steps = len(val_df)/BATCH, verbose = 0)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-09-21T07:32:59.541808Z",
     "iopub.status.busy": "2021-09-21T07:32:59.541306Z",
     "iopub.status.idle": "2021-09-21T07:33:11.537571Z",
     "shell.execute_reply": "2021-09-21T07:33:11.536848Z",
     "shell.execute_reply.started": "2021-09-21T07:32:59.541759Z"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(ds_test, steps = len(df_test), verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:22.266371Z",
     "iopub.status.busy": "2021-09-21T08:52:22.264464Z",
     "iopub.status.idle": "2021-09-21T08:52:22.275386Z",
     "shell.execute_reply": "2021-09-21T08:52:22.274556Z",
     "shell.execute_reply.started": "2021-09-21T08:52:22.266332Z"
    }
   },
   "outputs": [],
   "source": [
    "num_label = {'Normal': 0, 'Pneumonia' : 1}\n",
    "Y_test = df_test['class'].copy().map(num_label).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:22.280022Z",
     "iopub.status.busy": "2021-09-21T08:52:22.278653Z",
     "iopub.status.idle": "2021-09-21T08:52:40.368433Z",
     "shell.execute_reply": "2021-09-21T08:52:40.367682Z",
     "shell.execute_reply.started": "2021-09-21T08:52:22.279987Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_test.reset()\n",
    "predictions = model.predict(ds_test, steps=len(ds_test), verbose=0)\n",
    "pred_labels= np.where(predictions>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:40.369810Z",
     "iopub.status.busy": "2021-09-21T08:52:40.369536Z",
     "iopub.status.idle": "2021-09-21T08:52:40.379306Z",
     "shell.execute_reply": "2021-09-21T08:52:40.378505Z",
     "shell.execute_reply.started": "2021-09-21T08:52:40.369769Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: \", accuracy_score(Y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:40.382218Z",
     "iopub.status.busy": "2021-09-21T08:52:40.382026Z",
     "iopub.status.idle": "2021-09-21T08:52:40.596093Z",
     "shell.execute_reply": "2021-09-21T08:52:40.595419Z",
     "shell.execute_reply.started": "2021-09-21T08:52:40.382196Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(Y_test, pred_labels)\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\", fontsize= 12)\n",
    "plt.ylabel(\"True Label\", fontsize= 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:40.597617Z",
     "iopub.status.busy": "2021-09-21T08:52:40.597366Z",
     "iopub.status.idle": "2021-09-21T08:52:40.608447Z",
     "shell.execute_reply": "2021-09-21T08:52:40.607586Z",
     "shell.execute_reply.started": "2021-09-21T08:52:40.597583Z"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(Y_test, pred_labels, labels = [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-21T08:52:40.610070Z",
     "iopub.status.busy": "2021-09-21T08:52:40.609803Z",
     "iopub.status.idle": "2021-09-21T08:52:40.798635Z",
     "shell.execute_reply": "2021-09-21T08:52:40.797989Z",
     "shell.execute_reply.started": "2021-09-21T08:52:40.610036Z"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc = metrics.roc_auc_score(Y_test, predictions)\n",
    "print('ROC_AUC: ', roc_auc)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC_AUC = %0.3f' % roc_auc)\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\", fontsize= 12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize= 12)\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall was close to 100%. Even without expertise on the medical field, itâ€™s reasonable to assume that false negatives are more â€˜costlyâ€™ than false positives in this case. Reaching such recall with a relatively small dataset for training as this one, while also reaching a pretty good recall, is a good indicative of the modelâ€™s capabilities. Such capabilities are also confirmed by the high ROC-AUC value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"9\">References</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "- https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/03_convolutional_neural_networks_in_tensorflow.ipynb\n",
    "- https://www.tensorflow.org/guide/keras/transfer_learning\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "- https://keras.io/api/applications/\n",
    "- https://keras.io/api/applications/resnet/#resnet152v2-function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
