{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational API with GPT-3\n",
    "\n",
    "**Description:** An example of a chatbot using GPT-3<br>\n",
    "**Dataset:** We created a training dataset to define the Persona : Martin  <br>\n",
    "The datasets contain two columns. First Column has questions and second its answers, in this way we describe the personality of a person that will become the chatbot later\n",
    "\n",
    "https://github.com/reach-the-sky/GPT3-Chatbot/blob/main/GPT3-ChatBot.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai as ai\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "f = open('./api-keys.json')\n",
    "data = json.load(f)\n",
    "for v in data.values():\n",
    "   token = v['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train batch a .csv file with two columns Question/Answer is required\n",
      "\n",
      "Do you want to train the openai chatbot (True/False/Batch): Martin\n",
      "\n",
      "-processed questions: 0\n",
      "\n",
      "Enter the questions to openai (to quit type \"stop\")\n",
      "Question: what is your preferred food\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "you exceeded your current quota, please check your plan and billing details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6001/2912972772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_chat_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6001/2912972772.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(question, chat_log)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mchat_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_chat_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{chat_log}Human: {question}\\nAI:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     response = completion.create(prompt = prompt, engine =  \"davinci\", \n\u001b[0m\u001b[1;32m      8\u001b[0m                                  \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                  presence_penalty=0.7, best_of=1, max_tokens=100,stop = \"\\nHuman: \")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         )\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: you exceeded your current quota, please check your plan and billing details"
     ]
    }
   ],
   "source": [
    "ai.api_key = token\n",
    "\n",
    "def chat(question,chat_log = None) -> str:\n",
    "    if(chat_log == None):\n",
    "        chat_log = start_chat_log\n",
    "    prompt = f\"{chat_log}Human: {question}\\nAI:\"\n",
    "    response = completion.create(prompt = prompt, engine =  \"davinci\", \n",
    "                                 temperature = 0.75,top_p=1, frequency_penalty=0.2, \n",
    "                                 presence_penalty=0.7, best_of=1, max_tokens=100,stop = \"\\nHuman: \")\n",
    "    return response.choices[0].text\n",
    "\n",
    "def modify_start_message(chat_log,question,answer) -> str:\n",
    "    if chat_log == None:\n",
    "        chat_log = start_chat_log\n",
    "    chat_log += f\"Human: {question}\\nAI: {answer}\\n\"\n",
    "    return chat_log\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    i=0\n",
    "    completion = ai.Completion()\n",
    "\n",
    "    start_chat_log = \"\"\"Human: Hello, I am Human.\n",
    "    AI: Hello, human I am openai gpt3.\n",
    "    Human: How are you?\n",
    "    AI: I am fine, thanks for asking. \n",
    "    \"\"\"\n",
    "    print('To train batch a .csv file with two columns Question/Answer is required')\n",
    "    train = input(\"\\nDo you want to train the openai chatbot (True/False/Batch): \")\n",
    "    if(train == \"True\"):\n",
    "        print(\"\\n(To stop the training enter stop in the qestion)\\n\")\n",
    "        while(True):\n",
    "            question = input(\"Question: \")\n",
    "            if question == \"stop\":\n",
    "                break\n",
    "            answer = input(\"Answer: \")\n",
    "            start_chat_log = modify_start_message(start_chat_log,question,answer)\n",
    "            print(\"\\n\")\n",
    "    elif (train == 'Batch'):\n",
    "        file_name = input(\"name of the file for training (without .csv)\")\n",
    "        q_and_a = pd.read_csv(file_name+'.csv',index_col=False)\n",
    "        for index, row in q_and_a.iterrows():\n",
    "           i = i+1\n",
    "           start_chat_log = modify_start_message(start_chat_log,row['Question'],row['Answer'])\n",
    "    print()\n",
    "    print('-processed questions:',i)\n",
    "    question = \"\"\n",
    "    print(\"\\nEnter the questions to openai (to quit type \\\"stop\\\")\")\n",
    "    while True:\n",
    "        question = input(\"Question: \")\n",
    "        if question == \"stop\":\n",
    "            break\n",
    "        print(\"AI: \",chat(question,start_chat_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your name?</td>\n",
       "      <td>Martin McFly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How old are you?</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is your job?</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is your favorite sport?</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is your favorite football player?</td>\n",
       "      <td>Messi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is your favorite Football team?</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When is your birthday</td>\n",
       "      <td>23 april 1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your favorite food</td>\n",
       "      <td>Pizza pepperoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What sports do you practice</td>\n",
       "      <td>Ski, ice hockey and windsurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>popular wisdom</td>\n",
       "      <td>A bird in the hand is worth two in the bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>best car</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do you spend summers</td>\n",
       "      <td>Menorca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Where do you sail</td>\n",
       "      <td>menorca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Question  \\\n",
       "0                     What is your name?    \n",
       "1                        How old are you?   \n",
       "2                       What is your job?   \n",
       "3            what is your favorite sport?   \n",
       "4   Who is your favorite football player?   \n",
       "5    What is your favorite Football team?   \n",
       "6                   When is your birthday   \n",
       "7                      your favorite food   \n",
       "8            What sports do you practice    \n",
       "9                          popular wisdom   \n",
       "10                               best car   \n",
       "11             Where do you spend summers   \n",
       "12                     Where do you sail    \n",
       "\n",
       "                                         Answer  \n",
       "0                                  Martin McFly  \n",
       "1                                            25  \n",
       "2                                       Student  \n",
       "3                                      football  \n",
       "4                                         Messi  \n",
       "5                               Manchester City  \n",
       "6                                 23 april 1996  \n",
       "7                               Pizza pepperoni  \n",
       "8                  Ski, ice hockey and windsurf  \n",
       "9   A bird in the hand is worth two in the bush  \n",
       "10                                        Tesla  \n",
       "11                                      Menorca  \n",
       "12                                      menorca  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_and_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
